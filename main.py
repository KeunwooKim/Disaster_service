import os
import sys
import time
import json
import csv
import logging
import select
import re
import threading
from datetime import datetime, timezone, timedelta
from io import StringIO
from uuid import uuid4, uuid5, NAMESPACE_DNS
from dotenv import load_dotenv

import requests
import xmltodict
import xml.etree.ElementTree as ET
from bs4 import BeautifulSoup
from konlpy.tag import Okt  # í˜•íƒœì†Œ ë¶„ì„ê¸°

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.chrome.service import Service
import pandas as pd
from functools import partial
from ner_utils import extract_locations

import firebase_admin
from firebase_admin import credentials
from firebase_admin import messaging

# .env íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ì§€ì •í•˜ì—¬ ë¡œë“œ
dotenv_path = os.path.join(os.path.dirname(__file__), '.env')
if os.path.exists(dotenv_path):
    load_dotenv(dotenv_path)
    logging.info(f".env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤: {dotenv_path}")
else:
    logging.warning(f".env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {dotenv_path}")

# Firebase ì´ˆê¸°í™”
cred_path = os.getenv("FIREBASE_CRED_PATH")
if not cred_path:
    logging.critical("FIREBASE_CRED_PATH í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Firebase Admin SDKë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    sys.exit(1)

if not os.path.exists(cred_path):
    logging.critical(f"Firebase ì¸ì¦ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {cred_path}")
    sys.exit(1)

try:
    cred = credentials.Certificate(cred_path)
    firebase_admin.initialize_app(cred)
    logging.info("âœ… Firebase Admin SDKê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
except Exception as e:
    logging.critical(f"âŒ Firebase Admin SDK ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    sys.exit(1)

# ---------------------------------------------------------------------------
# ì„¤ì • ë° ì „ì—­ë³€ìˆ˜
# ---------------------------------------------------------------------------
load_dotenv()
API_KEY = os.getenv("API_KEY", "7dWUeNJAqaan8oJAs5CbDWKnWaJpLWoxd+lB97UDDRgFfSjfKD7ZGHxM+kRAoZqsga+WlheugBMS2q9WCSaUNg==")
EQ_API_KEY = os.getenv("EQ_API_KEY", "F5Iz7aHpRUSSM-2h6ZVE2w")
CHROME_DRIVER_PATH = '/usr/local/bin/chromedriver'

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logging.getLogger('cassandra').setLevel(logging.ERROR)

# í˜•íƒœì†Œ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
okt = Okt()

# API í˜¸ì¶œ ì‹œ ì„¸ì…˜ ì¬ì‚¬ìš©
session_http = requests.Session()

# FCM ì•Œë¦¼ ì „ì—­ ìƒíƒœ í”Œë˜ê·¸
FCM_NOTIFICATIONS_ENABLED = True

# ìœ íš¨í•˜ì§€ ì•Šì€ FCM í† í°ì„ ì„ì‹œ ì €ì¥í•˜ëŠ” ì§‘í•© (ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ë™ì•ˆë§Œ ìœ ì§€)
INVALID_FCM_TOKENS = set()

# ìƒìˆ˜ ì •ì˜
STATION_CODES = {
    90: "ì†ì´ˆ", 93: "ë¶ì¶˜ì²œ", 95: "ì² ì›", 96: "ë…ë„", 98: "ë™ë‘ì²œ",
    99: "íŒŒì£¼", 100: "ëŒ€ê´€ë ¹", 101: "ì¶˜ì²œ", 102: "ë°±ë ¹ë„", 104: "ë¶ê°•ë¦‰",
    105: "ê°•ë¦‰", 106: "ë™í•´", 108: "ì„œìš¸", 112: "ì¸ì²œ", 114: "ì›ì£¼",
    115: "ìš¸ë¦‰ë„", 116: "ê´€ì•…(ë ˆ)", 119: "ìˆ˜ì›", 121: "ì˜ì›”", 127: "ì¶©ì£¼",
    129: "ì„œì‚°", 130: "ìš¸ì§„", 131: "ì²­ì£¼", 133: "ëŒ€ì „", 135: "ì¶”í’ë ¹",
    136: "ì•ˆë™", 137: "ìƒì£¼", 138: "í¬í•­", 140: "êµ°ì‚°", 143: "ëŒ€êµ¬",
    146: "ì „ì£¼", 155: "ì°½ì›", 156: "ê´‘ì£¼", 162: "í†µì˜", 165: "ëª©í¬",
    168: "ì—¬ìˆ˜", 169: "í‘ì‚°ë„", 170: "ì™„ë„", 172: "ê³ ì°½", 174: "ìˆœì²œ",
    175: "ì§„ë„(ë ˆ)", 177: "í™ì„±", 184: "ì œì£¼", 185: "ê³ ì‚°", 188: "ì„±ì‚°",
    189: "ì„œê·€í¬", 192: "ì§„ì£¼", 201: "ê°•í™”", 202: "ì–‘í‰", 203: "ì´ì²œ",
    211: "ì¸ì œ", 212: "í™ì²œ", 216: "íƒœë°±", 217: "ì •ì„ êµ°", 221: "ì œì²œ",
    226: "ë³´ì€", 229: "ë¶ê²©ë ¬ë¹„ë„", 232: "ì²œì•ˆ", 235: "ë³´ë ¹", 236: "ë¶€ì—¬",
    238: "ê¸ˆì‚°", 239: "ì„¸ì¢…", 243: "ë¶€ì•ˆ", 244: "ì„ì‹¤", 245: "ì •ì",
    247: "ë‚¨ì›", 248: "ì¥ìˆ˜", 251: "ê³ ì°½êµ°", 252: "ì˜ê´‘êµ°", 253: "ê¹€í•´ì‹œ",
    254: "ìˆœì°½êµ°", 255: "ë¶ì°½ì›", 257: "ì–‘ì‚°ì‹œ", 258: "ë³´ì„±êµ°", 259: "ê°•ì§„êµ°",
    260: "ì¥í¥", 261: "í•´ë‚¨", 262: "ê³ í¥", 263: "ì˜ë ¹êµ°", 264: "í•¨ì–‘êµ°",
    266: "ê´‘ì–‘ì‹œ", 268: "ì§„ë„êµ°", 271: "ë´‰í™”", 272: "ì˜ì£¼", 273: "ë¬¸ê²½",
    276: "ì²­ì†¡êµ°", 277: "ì˜ë•", 278: "ì˜ì„±", 279: "êµ¬ë¯¸", 281: "ì˜ì²œ",
    283: "ê²½ì£¼ì‹œ", 284: "ê±°ì°½", 285: "í•©ì²œ", 288: "ë°€ì–‘", 289: "ì‚°ì²­",
    294: "ê±°ì œ", 295: "ë‚¨í•´", 296: "ë¶ë¶€ì‚°", 300: "ë§ë„", 301: "ì„ìë„",
    302: "ì¥ì‚°ë„", 303: "ê°€ê±°ë„", 304: "ì‹ ì§€ë„", 305: "ì—¬ì„œë„", 306: "ì†Œë¦¬ë„",
    308: "ì˜¥ë„", 310: "ê¶ì´Œ", 311: "ê°€ì•¼ì‚°", 312: "ì£¼ì™•ì‚°", 313: "ì–‘ì§€ì•”",
    314: "ë•ìœ ë´‰", 315: "ì„±ì‚¼ì¬", 316: "ë¬´ë“±ì‚°", 317: "ëª¨ì•…ì‚°", 318: "ìš©í‰",
    319: "ì²œë¶€", 320: "í–¥ë¡œë´‰", 321: "ì›í†µ", 322: "ìƒì„œ", 323: "ë§ˆí˜„",
    324: "ì†¡ê³„", 325: "ë°±ìš´", 326: "ìš©ë¬¸ì‚°", 327: "ìš°ì•”ì‚°", 328: "ì¤‘ë¬¸",
    329: "ì‚°ì²œë‹¨", 330: "ëŒ€í˜", 351: "ë‚¨ë©´", 352: "ì¥í¥ë©´", 353: "ë•ì •ë™",
    355: "ì„œíƒ„ë©´", 356: "ê³ ë•ë©´", 358: "í˜„ë•ë©´", 359: "ì„ ë‹¨ë™", 360: "ë‚´ì´Œë©´",
    361: "ì˜ì¤‘ë©´", 364: "ë¶„ë‹¹êµ¬", 365: "ì„ìˆ˜ë™", 366: "ì˜¤ì „ë™", 367: "ì‹ í˜„ë™",
    368: "ìˆ˜íƒë™", 369: "ìˆ˜ë¦¬ì‚°ê¸¸", 370: "ì´ë™ë¬µë¦¬", 371: "ê¸°í¥êµ¬", 372: "ì€í˜„ë©´",
    373: "ë‚¨ë°©", 374: "ì²­ë¶", 375: "ë°±ì„ì", 400: "ê°•ë‚¨", 401: "ì„œì´ˆ",
    402: "ê°•ë™", 403: "ì†¡íŒŒ", 404: "ê°•ì„œ", 405: "ì–‘ì²œ", 406: "ë„ë´‰",
    407: "ë…¸ì›", 408: "ë™ëŒ€ë¬¸", 409: "ì¤‘ë‘", 410: "ê¸°ìƒì²­", 411: "ë§ˆí¬",
    412: "ì„œëŒ€ë¬¸", 413: "ê´‘ì§„", 414: "ì„±ë¶", 415: "ìš©ì‚°", 416: "ì€í‰",
    417: "ê¸ˆì²œ", 418: "í•œê°•", 419: "ì¤‘êµ¬", 421: "ì„±ë™", 423: "êµ¬ë¡œ",
    424: "ê°•ë¶", 425: "ë‚¨í˜„", 426: "ë°±ë ¹(ë ˆ)", 427: "ê¹€í¬ì¥ê¸°", 428: "í•˜ë‚¨ë•í’",
    430: "ê²½ê¸°", 431: "ì‹ ê³¡", 432: "í–¥ë‚¨", 433: "ë¶€ì²œ", 434: "ì•ˆì–‘",
    435: "ê³ ì”", 436: "ì—­ì‚¼", 437: "ê´‘ëª…", 438: "êµ°í¬", 439: "ì§„ì•ˆ",
    440: "ì„¤ë´‰", 441: "ê¹€í¬", 442: "ì§€ì›”", 443: "ë³´ê°œ", 444: "í•˜ë‚¨",
    445: "ì˜ì™•", 446: "ë‚¨ì´Œ", 447: "ë¶ë‚´", 448: "ì‚°ë¶", 449: "ì˜¥ì²œ",
    450: "ì£¼êµ", 451: "ì˜¤ë‚¨", 452: "ì‹ ë¶", 453: "ì†Œí•˜", 454: "í•˜ë´‰ì•”",
    455: "ìë‚´", 456: "ì—°ì²œ", 457: "ì¶˜ê¶", 458: "í‡´ì´Œ", 459: "ì˜¤í¬",
    460: "ì‹¤ì´Œ", 461: "ë§ˆì¥", 462: "ëª¨ê°€", 463: "í¥ì²œ", 464: "ì ë™",
    465: "ê°€ë‚¨", 466: "ê¸ˆì‚¬", 467: "ì–‘ì„±", 468: "ì„œìš´", 469: "ì¼ì£½",
    470: "ê³ ì‚¼", 471: "ì†¡íƒ„", 472: "í¬ìŠ¹", 473: "ê°€ì‚°", 474: "ì˜ë¶",
    475: "ê´€ì¸", 476: "í™”í˜„", 477: "ìƒíŒ¨", 478: "ì™•ì§•", 479: "ì¥ë‚¨"
}
WARNING_CODES = {  # ì¬ë‚œ ì½”ë“œ ë§¤í•‘
    "í˜¸ìš°": 32,
    "ê°•í’": 34,
    "ëŒ€ì„¤": 35,
    "í­ì—¼": 41,
    "í•œíŒŒ": 42
}
FLOOD_CODE = 33
TYPHOON_CODE = 31

# â€”â€”â€” ë‹¤ë¦¬ ì¢Œí‘œ CSV ë¡œë“œ â€”â€”â€”
# korea_bridge_info.csv ì—ëŠ” columns: ['bridge', 'bridge_lat', 'bridge_lon']
bridge_df = pd.read_csv("data/korea_bridge_info.csv", encoding="utf-8")
bridge_df = bridge_df.drop_duplicates(subset="bridge")  # ì¤‘ë³µ ì œê±°
bridge_coords = bridge_df.set_index("bridge")[["bridge_lat", "bridge_lon"]].to_dict("index")


# ---------------------------------------------------------------------------
# [ìƒˆë¡œìš´ ë¶€ë¶„] ìŠ¤ì¼€ì¤„ëŸ¬ í´ë˜ìŠ¤
# ---------------------------------------------------------------------------
class TaskScheduler:
    def __init__(self):
        """
        tasks: { task_name: { "interval": seconds, "last_run": timestamp, "function": callable } }
        """
        self.tasks = {}
        self.stop_event = threading.Event()
        self.thread = threading.Thread(target=self.run, daemon=True)

    def add_task(self, name: str, interval: int, function):
        self.tasks[name] = {"interval": interval, "last_run": 0, "function": function}
        logging.info(f"ìŠ¤ì¼€ì¤„ëŸ¬ì— ì‘ì—… ì¶”ê°€ë¨: {name} (ì£¼ê¸°: {interval}ì´ˆ)")

    def update_interval(self, name: str, interval: int) -> bool:
        if name in self.tasks:
            self.tasks[name]["interval"] = interval
            logging.info(f"{name}ì˜ ì£¼ê¸°ë¥¼ {interval}ì´ˆë¡œ ìˆ˜ì •")
            return True
        return False

    def list_tasks(self):
        return {name: task["interval"] for name, task in self.tasks.items()}

    def run(self):
        while not self.stop_event.is_set():
            now = time.time()
            for name, task in self.tasks.items():
                if now - task["last_run"] >= task["interval"]:
                    logging.info(f"[ìŠ¤ì¼€ì¤„ëŸ¬] {name} ì‘ì—… ì‹¤í–‰")
                    try:
                        task["function"]()
                    except Exception as e:
                        logging.error(f"[ìŠ¤ì¼€ì¤„ëŸ¬] {name} ì‘ì—… ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                    task["last_run"] = now
            time.sleep(1)

    def start(self):
        self.thread.start()

    def stop(self):
        self.stop_event.set()
        self.thread.join()


# ì „ì—­ ìŠ¤ì¼€ì¤„ëŸ¬ ì¸ìŠ¤í„´ìŠ¤
scheduler = TaskScheduler()


# ---------------------------------------------------------------------------
# ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ---------------------------------------------------------------------------
def is_in_korea(lat, lon):
    """ì£¼ì–´ì§„ ì¢Œí‘œê°€ ëŒ€í•œë¯¼êµ­ ì˜í†  ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    if lat is None or lon is None:
        return False
    # ëŒ€í•œë¯¼êµ­ ìœ„ë„: 33 ~ 39, ê²½ë„: 124 ~ 132
    return (33.0 <= lat <= 39.0) and (124.0 <= lon <= 132.0)


def kst_to_utc(dt_str: str, fmt: str) -> datetime:
    """KST ì‹œê°„ ë¬¸ìì—´ì„ UTC datetime ê°ì²´ë¡œ ë³€í™˜"""
    kst = timezone(timedelta(hours=9))
    local_dt = datetime.strptime(dt_str, fmt).replace(tzinfo=kst)
    return local_dt.astimezone(timezone.utc)


def execute_cassandra(query: str, params: tuple):
    """Cassandra ì¿¼ë¦¬ ì‹¤í–‰ì„ ìœ„í•œ ê³µí†µ í•¨ìˆ˜"""
    from cassandra.query import SimpleStatement
    try:
        connector.session.execute(SimpleStatement(query), params)
        return True
    except Exception as e:
        logging.error(f"Cassandra ì¿¼ë¦¬ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        return False

def send_fcm_notification(token: str, title: str, body: str):
    global INVALID_FCM_TOKENS
    if token in INVALID_FCM_TOKENS:
        return

    try:
        message = messaging.Message(
            notification=messaging.Notification(
                title=title,
                body=body,
            ),
            token=token,
        )
        response = messaging.send(message)
        logging.info(f"FCM ë©”ì‹œì§€ ì „ì†¡ ì„±ê³µ (token: {token[:10]}..., response: {response})")
    except Exception as e:
        error_message = str(e).lower()
        if 'registration-token-not-registered' in error_message or 'invalid-argument' in error_message or 'was not found' in error_message or 'not a valid fcm registration token' in error_message:
            logging.warning(f"FCM í† í°ì´ ìœ íš¨í•˜ì§€ ì•Šì•„, ì´ë²ˆ ì‹¤í–‰ì—ì„œëŠ” ë‹¤ì‹œ ì‹œë„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (token: {token[:10]}...).")
            INVALID_FCM_TOKENS.add(token)
        else:
            logging.error(f"FCM ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨ (token: {token[:10]}...): {e}")


# ---------------------------------------------------------------------------
# Cassandra ì—°ê²° í´ë˜ìŠ¤
# ---------------------------------------------------------------------------
class CassandraConnector:
    def __init__(self, keyspace="disaster_service"):
        self.keyspace = keyspace
        self.cluster = None
        self.session = None
        self.setup_cassandra_connection()

    def setup_cassandra_connection(self):
        for attempt in range(5):
            try:
                logging.info(f"Cassandra ì—°ê²° ì‹œë„ ì¤‘... (ì‹œë„ {attempt + 1}/5)")
                from cassandra.auth import PlainTextAuthProvider
                from cassandra.cluster import Cluster
                auth_provider = PlainTextAuthProvider(username="andy013", password="1212")
                self.cluster = Cluster(["127.0.0.1"], port=9042, auth_provider=auth_provider)
                self.session = self.cluster.connect(self.keyspace)
                logging.info("âœ… Cassandra ì—°ê²° ì™„ë£Œ.")
                return
            except Exception as e:
                logging.error(f"âŒ Cassandra ì—°ê²° ì‹¤íŒ¨: {e}")
                time.sleep(10)
        raise Exception("Cassandra ì—°ê²° ì‹¤íŒ¨")


connector = CassandraConnector()

# ---------------------------------------------------------------------------
# ì§€ì˜¤ì½”ë”© ë° í–‰ì •êµ¬ì—­ ì½”ë“œ ì¡°íšŒ
# ---------------------------------------------------------------------------
import json
import os
import re
import logging
from datetime import datetime
from geopy.geocoders import Nominatim
import ssl, certifi

# ê²½ê³  ì œê±° ë° ì¸ì¦ ìš°íšŒ ì„¤ì •
ssl_context = ssl.create_default_context(cafile=certifi.where())
ssl_context.check_hostname = False
ssl_context.verify_mode = ssl.CERT_NONE

# ìºì‹œ íŒŒì¼ ê²½ë¡œ
GEO_CACHE_PATH = "geocode_cache.json"
FAILED_LOG_PATH = "failed_geocodes.log"

# ì§€ì˜¤ì½”ë”© ê°ì²´ ì´ˆê¸°í™”
geolocator = Nominatim(user_agent='South Korea')

# ìºì‹œ ë¡œë“œ
if os.path.exists(GEO_CACHE_PATH):
    with open(GEO_CACHE_PATH, "r", encoding="utf-8") as f:
        geocode_cache = json.load(f)
else:
    geocode_cache = {}

# ìºì‹œ ì €ì¥ í•¨ìˆ˜
def save_geocode_cache():
    try:
        with open(GEO_CACHE_PATH, "w", encoding="utf-8") as f:
            json.dump(geocode_cache, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logging.warning(f"[ìºì‹œ ì €ì¥ ì‹¤íŒ¨] {e}")

# ì§€ì˜¤ì½”ë”© í•¨ìˆ˜
def geocoding(address: str) -> dict:
    if not address:
        return {"lat": None, "lng": None}

    # ê´„í˜¸ ì œê±°
    cleaned_address = re.sub(r"\(.*\)", "", address).strip()

    # ìºì‹œ ì¡°íšŒ
    if cleaned_address in geocode_cache:
        return geocode_cache[cleaned_address]

    # ì§€ì˜¤ì½”ë”© ìš”ì²­
    try:
        location = geolocator.geocode(cleaned_address, timeout=5)
        if location:
            coords = {"lat": location.latitude, "lng": location.longitude}
            # ëŒ€í•œë¯¼êµ­ ë²”ìœ„ í™•ì¸
            if is_in_korea(coords['lat'], coords['lng']):
                geocode_cache[cleaned_address] = coords
                save_geocode_cache()
                return coords
            else:
                logging.warning(f"[ì§€ì˜¤ì½”ë”© ë²”ìœ„ ë²—ì–´ë‚¨] ({cleaned_address}): {coords['lat']}, {coords['lng']}")
                # ë²”ìœ„ ë²—ì–´ë‚œ ê²½ìš°ë„ ìºì‹±í•˜ì—¬ ë°˜ë³µ ìš”ì²­ ë°©ì§€
                geocode_cache[cleaned_address] = {"lat": None, "lng": None}
                save_geocode_cache()
                return {"lat": None, "lng": None}
    except Exception as e:
        logging.warning(f"[ì§€ì˜¤ì½”ë”© ì‹¤íŒ¨] ({cleaned_address}): {e}")
        with open(FAILED_LOG_PATH, "a", encoding="utf-8") as f:
            f.write(f"{datetime.now()} | ì‹¤íŒ¨ ì£¼ì†Œ: {cleaned_address}\n")

    return {"lat": None, "lng": None}


# í–‰ì •êµ¬ì—­ ì½”ë“œ ì¡°íšŒ
REGION_CACHE_PATH = "regioncode_cache.json"
REGION_FAIL_LOG = "failed_regioncodes.log"

if os.path.exists(REGION_CACHE_PATH):
    with open(REGION_CACHE_PATH, "r", encoding="utf-8") as f:
        region_cache = json.load(f)
else:
    region_cache = {}

def save_region_cache():
    try:
        with open(REGION_CACHE_PATH, "w", encoding="utf-8") as f:
            json.dump(region_cache, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logging.warning(f"[ì§€ì—­ ìºì‹œ ì €ì¥ ì‹¤íŒ¨] {e}")

def get_regioncode(address: str) -> int:
    if not address:
        return None

    # ê´„í˜¸ ì œê±°
    cleaned_address = re.sub(r"\(.*\)", "", address).strip()

    # ìºì‹œ ì¡°íšŒ
    if cleaned_address in region_cache:
        return region_cache[cleaned_address]

    # API ìš”ì²­
    url = 'http://apis.data.go.kr/1741000/StanReginCd/getStanReginCdList'
    params = {
        'serviceKey': API_KEY,
        'pageNo': '1',
        'numOfRows': '1',
        'type': 'xml',
        'locatadd_nm': cleaned_address,
    }
    try:
        resp = session_http.get(url, params=params, timeout=5)
        resp.raise_for_status()
        root = ET.fromstring(resp.content)
        row = root.find('.//row')
        if row is not None:
            region_cd = int(row.findtext('locathigh_cd') or 0)
            region_cache[cleaned_address] = region_cd
            save_region_cache()
            return region_cd
    except Exception as e:
        logging.warning(f"[í–‰ì •ì½”ë“œ ì¡°íšŒ ì‹¤íŒ¨] ({cleaned_address}): {e}")
        with open(REGION_FAIL_LOG, "a", encoding="utf-8") as f:
            f.write(f"{datetime.now()} | ì‹¤íŒ¨ ì£¼ì†Œ: {cleaned_address}\n")

    return None


# ---------------------------------------------------------------------------
# í†µí•© ë°ì´í„° ì €ì¥ í•¨ìˆ˜
# ---------------------------------------------------------------------------
def insert_rtd_data(rtd_code, rtd_time, rtd_loc, rtd_details,
                    regioncode=None, latitude=None, longitude=None):
    record_str = f"{rtd_code}_{rtd_time.strftime('%Y%m%d%H%M%S')}_{rtd_loc}_{'_'.join(rtd_details)}"
    rec_id = uuid5(NAMESPACE_DNS, record_str)
    q = """
    INSERT INTO rtd_db (
      rtd_code, rtd_time, id, rtd_loc, rtd_details,
      regioncode, latitude, longitude
    ) VALUES (%s,%s,%s,%s,%s,%s,%s,%s) IF NOT EXISTS
    """
    params = (
        rtd_code, rtd_time, rec_id, rtd_loc, rtd_details,
        regioncode, latitude, longitude
    )
    if execute_cassandra(q, params):
        logging.info(f"RTD ì €ì¥ ì„±ê³µ: {rec_id}")

        # FCM ì•Œë¦¼ ë°œì†¡ ë¡œì§ ì¶”ê°€ (FCM_NOTIFICATIONS_ENABLEDê°€ Trueì¼ ë•Œë§Œ)
        global FCM_NOTIFICATIONS_ENABLED
        if FCM_NOTIFICATIONS_ENABLED:
            title = "ì¬ë‚œ ì•Œë¦¼"
            body = f"ìƒˆë¡œìš´ ì¬ë‚œ ì •ë³´ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {rtd_loc} - {', '.join(rtd_details)}"

            # rtd_codeì— ë”°ë¥¸ ì•Œë¦¼ ë‚´ìš© ì»¤ìŠ¤í„°ë§ˆì´ì§•
            if rtd_code == 72: # ëŒ€ê¸°ì§ˆ ì˜ˆë³´
                title = "ëŒ€ê¸°ì§ˆ ì˜ˆë³´ ì•Œë¦¼"
                body = f"[{rtd_loc}] ëŒ€ê¸°ì§ˆ ì˜ˆë³´: {', '.join(rtd_details)}"
            elif rtd_code == 71: # ì‹¤ì‹œê°„ ëŒ€ê¸°ì§ˆ ë“±ê¸‰
                title = "ì‹¤ì‹œê°„ ëŒ€ê¸°ì§ˆ ì•Œë¦¼"
                body = f"[{rtd_loc}] ì‹¤ì‹œê°„ ëŒ€ê¸°ì§ˆ: {', '.join(rtd_details)}"
            elif rtd_code == 51: # ì§€ì§„ ì •ë³´
                title = "ì§€ì§„ ë°œìƒ ì•Œë¦¼"
                body = f"[{rtd_loc}] ì§€ì§„ ë°œìƒ: {', '.join(rtd_details)}"
            elif rtd_code == 31: # íƒœí’ ì •ë³´
                title = "íƒœí’ ì •ë³´ ì•Œë¦¼"
                body = f"[{rtd_loc}] íƒœí’ ì •ë³´: {', '.join(rtd_details)}"
            elif rtd_code == 33: # í™ìˆ˜ ì •ë³´
                title = "í™ìˆ˜ ì •ë³´ ì•Œë¦¼"
                body = f"[{rtd_loc}] í™ìˆ˜ ì •ë³´: {', '.join(rtd_details)}"
            elif rtd_code in WARNING_CODES.values(): # ê¸°ìƒíŠ¹ë³´
                title = "ê¸°ìƒíŠ¹ë³´ ì•Œë¦¼"
                body = f"[{rtd_loc}] ê¸°ìƒíŠ¹ë³´: {', '.join(rtd_details)}"
            elif rtd_code == 21: # ì¬ë‚œë¬¸ì
                title = "ì¬ë‚œë¬¸ì ì•Œë¦¼"
                body = f"[{rtd_loc}] ì¬ë‚œë¬¸ì: {', '.join(rtd_details)}"

            # user_device í…Œì´ë¸”ì—ì„œ ëª¨ë“  device_token ì¡°íšŒ -> ë‹¨ì¼ í† í°ìœ¼ë¡œ ë³€ê²½
            try:
                # device_tokens_query = "SELECT device_token FROM user_device"
                # device_tokens_rows = connector.session.execute(device_tokens_query)
                # for token_row in device_tokens_rows:
                #     if token_row.device_token:
                #         send_fcm_notification(token_row.device_token, title, body)
                
                registration_token = 'd35HBpkSQnSgjtl3_EFM7F:APA91bG_q4ZD4oQphddswdda8hmeJq2wg17z9fVAGEjEvs5rY45fSIyYZ7elPgtCJeG8xryrfVnJcZ6PvrUGqSZqxndX7kExsKuR8Qs_rJrtPZogfcAUgiMKk'
                send_fcm_notification(registration_token, title, body)

            except Exception as e:
                logging.error(f"ë””ë°”ì´ìŠ¤ í† í° ì¡°íšŒ ë˜ëŠ” FCM ë°œì†¡ ì˜¤ë¥˜: {e}")

    else:
        logging.error(f"RTD ì €ì¥ ì‹¤íŒ¨: {rec_id}")

# ---------------------------------------------------------------------------
# 1. ëŒ€ê¸°ì§ˆ ì˜ˆë³´ ìˆ˜ì§‘ (rtd_code 72)
# ---------------------------------------------------------------------------
from cassandra.query import SimpleStatement
def get_air_inform():
    logging.info("ëŒ€ê¸°ì§ˆ ì˜ˆë³´ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    now = datetime.now()
    today = now.strftime("%Y-%m-%d")
    search_date = (now - timedelta(days=1)).strftime("%Y-%m-%d") if now.hour < 9 else today
    params = {
        "searchDate": search_date,
        "returnType": "xml",
        "numOfRows": "100",
        "pageNo": "1",
        "serviceKey": API_KEY
    }

    try:
        resp = session_http.get(
            "http://apis.data.go.kr/B552584/ArpltnInforInqireSvc/getMinuDustFrcstDspth",
            params=params, timeout=10
        )
        resp.raise_for_status()
        parsed = xmltodict.parse(resp.text)
    except Exception as e:
        logging.error(f"Air Inform API ì˜¤ë¥˜ ë˜ëŠ” íŒŒì‹± ì‹¤íŒ¨: {e}")
        return

    # ì•ˆì „í•˜ê²Œ ë”•ì…”ë„ˆë¦¬ êº¼ë‚´ê¸°
    response = parsed.get("response")
    if not response:
        logging.error("Air Inform API ì‘ë‹µì— <response> ìš”ì†Œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    body = response.get("body", {})
    items_container = body.get("items", {})
    items = items_container.get("item", [])

    if items is None:
        logging.info("ëŒ€ê¸°ì§ˆ ì˜ˆë³´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    if not isinstance(items, list):
        items = [items]

    for item in items:
        inform_date = item.get("informData", "").strip()
        if inform_date != today:
            continue

        try:
            dt = kst_to_utc(item["dataTime"].replace("ì‹œ ë°œí‘œ", "").strip(), "%Y-%m-%d %H")
        except:
            dt = datetime.now(timezone.utc)

        code = item.get("informCode", "")
        overall = item.get("informOverall", "")
        grade = item.get("informGrade", "")

        # PM25 ì˜ˆë³´ ì¤‘ 'ë‚˜ì¨' ì§€ì—­ì— ëŒ€í•´ RTD ì €ì¥
        if code == 'PM25' and 'ë‚˜ì¨' in overall:
            bad_regions = [seg.split(':')[0] for seg in grade.split(',') if 'ë‚˜ì¨' in seg]
            if bad_regions:
                rtd_details = [
                    f"code: {code}",
                    f"grade: {','.join(bad_regions)}"
                ]
                for region in bad_regions:
                    coords = geocoding(region)
                    region_cd = get_regioncode(region)
                    # â†“ ì—¬ê¸°ë§Œ ë°”ë€œ: print â†’ insert_rtd_data
                    insert_rtd_data(
                        72,
                        dt,
                        region,
                        rtd_details,
                        region_cd,
                        float(coords['lat']) if coords['lat'] else None,
                        float(coords['lng']) if coords['lng'] else None
                    )
            else:
                logging.info("ë‚˜ì¨ ë“±ê¸‰ ì§€ì—­ ì—†ìŒ")

    logging.info("ëŒ€ê¸°ì§ˆ ì˜ˆë³´ ìˆ˜ì§‘ ì™„ë£Œ")


# ---------------------------------------------------------------------------
# 2. ì‹¤ì‹œê°„ ëŒ€ê¸°ì§ˆ ë“±ê¸‰ ìˆ˜ì§‘ (rtd_code 71)
# ---------------------------------------------------------------------------
def get_air_grade():
    logging.info("ì‹¤ì‹œê°„ ëŒ€ê¸°ì§ˆ ë“±ê¸‰ ìˆ˜ì§‘ ì‹œì‘")
    params = {
        "sidoName": "ì „êµ­",
        "returnType": "xml",
        "serviceKey": API_KEY,
        "numOfRows": "1000",
        "pageNo": "1",
        "ver": "1.3"
    }
    try:
        resp = session_http.get(
            "http://apis.data.go.kr/B552584/ArpltnInforInqireSvc/getCtprvnRltmMesureDnsty",
            params=params, timeout=10
        )
        resp.raise_for_status()
    except Exception as e:
        logging.error(f"Air Grade API ì˜¤ë¥˜: {e}")
        return

    data = xmltodict.parse(resp.text)
    items = data.get("response", {}).get("body", {}).get("items", {}).get("item", [])
    if isinstance(items, dict):
        items = [items]

    for it in items:
        # ì‹œê°„ íŒŒì‹±
        try:
            dt = kst_to_utc(it["dataTime"], "%Y-%m-%d %H:%M")
        except:
            dt = datetime.now(timezone.utc)

        pm10 = int(it.get("pm10Grade1h") or 0)
        pm25 = int(it.get("pm25Grade1h") or 0)
        station = it.get("stationName", "").strip()
        sido = it.get("sidoName", "").strip()

        # ìœ„í—˜ ë“±ê¸‰ ì´ìƒì¸ ê²½ìš°ë§Œ RTD ì €ì¥
        if pm10 >= 3 or pm25 >= 3:
            rtd_details = [
                f"pm10_grade: {pm10}",
                f"pm25_grade: {pm25}",
                f"sido: {sido}",
                f"station: {station}"
            ]

            # 1) station ë‹¨ìœ„ ì¢Œí‘œ ì¡°íšŒ
            coords = geocoding(station)
            # 2) ì‹¤íŒ¨ ì‹œ sido ë‹¨ìœ„ ì¬ì¡°íšŒ
            if coords["lat"] is None:
                logging.info(f"'{station}' ì¢Œí‘œ ì—†ìŒ â†’ '{sido}'ë¡œ ì¬ì¡°íšŒ")
                coords = geocoding(sido)

            # í–‰ì •êµ¬ì—­ ì½”ë“œ ì¡°íšŒ
            region_cd = get_regioncode(station)

            # RTD ì €ì¥
            insert_rtd_data(
                71,
                dt,
                station,
                rtd_details,
                region_cd,
                float(coords["lat"]) if coords["lat"] else None,
                float(coords["lng"]) if coords["lng"] else None
            )

    logging.info("ì‹¤ì‹œê°„ ëŒ€ê¸°ì§ˆ ë“±ê¸‰ ìˆ˜ì§‘ ì™„ë£Œ")

# ---------------------------------------------------------------------------
# 3. ì§€ì§„ ì •ë³´ ìˆ˜ì§‘ (rtd_code 51)
# ---------------------------------------------------------------------------
def fetch_earthquake_data():
    logging.info("ì§€ì§„ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘")
    kst = timezone(timedelta(hours=9))
    current_time = datetime.now(kst).strftime('%Y%m%d%H%M%S')
    url = f"https://apihub.kma.go.kr/api/typ01/url/eqk_now.php?tm={current_time}&disp=0&help=1&authKey={EQ_API_KEY}"
    try:
        response = session_http.get(url, timeout=15)
        response.raise_for_status()
        logging.info("ì§€ì§„ API ì—°ê²° í™•ì¸")
        response.encoding = 'euc-kr'
        csv_data = csv.reader(StringIO(response.text))
    except Exception as e:
        logging.error(f"ì§€ì§„ API ì˜¤ë¥˜: {e}")
        return

    try:
        from cassandra.query import SimpleStatement
        max_time_result = connector.session.execute("SELECT eq_time FROM domestic_earthquake LIMIT 1")
        max_time_row = max_time_result.one()
        latest_eq_time = max_time_row.eq_time if max_time_row is not None else None
        if latest_eq_time and latest_eq_time.tzinfo is None:
            latest_eq_time = latest_eq_time.replace(tzinfo=timezone.utc)
    except Exception as e:
        logging.error(f"ì§€ì§„ ë°ì´í„° ìµœì‹  eq_time ì¡°íšŒ ì˜¤ë¥˜: {e}")
        latest_eq_time = None

    total_rows = 0
    saved_count = 0
    for row in csv_data:
        if not row or row[0].strip().startswith("#"):
            continue
        total_rows += 1

        tokens = " ".join(row).strip().split()
        if len(tokens) < 7:
            continue
        tp = tokens[0]
        if tp != "3":
            continue

        try:
            tm_eqk = tokens[3]
            dt = kst_to_utc(tm_eqk[:14], "%Y%m%d%H%M%S")
            if latest_eq_time and dt <= latest_eq_time:
                logging.info(f"ì´ë¯¸ ì €ì¥ëœ ìµœì‹  eq_time({latest_eq_time})ë³´ë‹¤ ì´ì „: {dt}")
                continue

            magnitude = float(tokens[4])
            lat_num = float(tokens[5])
            lon_num = float(tokens[6])
            location = " ".join(tokens[7:])
            msg = f"[{location}] ê·œëª¨ {magnitude}"

            record_str = f"{dt.strftime('%Y%m%d%H%M%S')}_{lat_num}_{lon_num}_{magnitude}"
            record_id = uuid5(NAMESPACE_DNS, record_str)

            insert_stmt = """
            INSERT INTO domestic_earthquake (eq_no, eq_time, eq_lat, eq_lot, eq_mag, eq_msg)
            VALUES (%s, %s, %s, %s, %s, %s) IF NOT EXISTS
            """
            if execute_cassandra(insert_stmt, (record_id, dt, lat_num, lon_num, magnitude, msg)):
                saved_count += 1
                rtd_details = [
                    f"magnitude: {magnitude}",
                    f"location: {location}",
                    f"latitude: {lat_num}",
                    f"longitude: {lon_num}"
                ]
                insert_rtd_data(51, dt, location, rtd_details)
            else:
                logging.error(f"ì§€ì§„ ì €ì¥ ì‹¤íŒ¨ (record: {record_str})")
        except Exception as e:
            logging.error(f"ì§€ì§„ íŒŒì‹± ì˜¤ë¥˜ (row: {row}): {e}")

    logging.info(f"ì§€ì§„ ì •ë³´ ì €ì¥ ì™„ë£Œ: {total_rows}í–‰ ì¤‘ {saved_count}ê±´ ì €ì¥ë¨")


# ---------------------------------------------------------------------------
# 4. íƒœí’ ì •ë³´ ìˆ˜ì§‘ (rtd_code 31)
# ---------------------------------------------------------------------------
last_forecast_time = None


def fetch_typhoon_data():
    global last_forecast_time
    kst = timezone(timedelta(hours=9))
    current_date = datetime.now(kst).strftime('%Y%m%d')
    url = 'http://apis.data.go.kr/1360000/TyphoonInfoService/getTyphoonInfo'
    params = {
        'serviceKey': 'D0I8CLciGzwIaBmM6g6XitlVfgkLBO83zDl4EnUUoxifvRlSZHu78BqoixtzJg17Gb06up+NHzPXjN0cA7sLOg==',
        'pageNo': '1',
        'numOfRows': '10',
        'dataType': 'XML',
        'fromTmFc': current_date,
        'toTmFc': current_date
    }
    try:
        response = session_http.get(url, params=params, timeout=10)
        response.raise_for_status()
    except Exception as e:
        logging.error(f"íƒœí’ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return []

    root = ET.fromstring(response.content)
    items = root.findall('.//item')
    if not items:
        logging.info("íƒœí’ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return []

    typhoon_data = []
    for item in items:
        forecast_time = item.findtext('tmFc')
        if not forecast_time or forecast_time == last_forecast_time:
            continue
        dt = kst_to_utc(forecast_time, "%Y%m%d%H%M")
        name = item.findtext('typName') or ""
        direction = item.findtext('typDir') or ""
        try:
            lat = float(item.findtext('typLat') or 0.0)
            lon = float(item.findtext('typLon') or 0.0)
        except Exception:
            lat, lon = 0.0, 0.0
        loc = item.findtext('typLoc') or ""
        intensity = item.findtext('typInt') or ""
        try:
            wind_radius = int(item.findtext('typ15') or 0)
        except Exception:
            wind_radius = 0

        typhoon_data.append({
            "forecast_time": dt,
            "typ_name": name,
            "typ_dir": direction,
            "typ_lat": lat,
            "typ_lon": lon,
            "typ_location": loc,
            "intensity": intensity,
            "wind_radius": wind_radius
        })
        last_forecast_time = forecast_time

    return typhoon_data


def get_typhoon_data():
    logging.info("íƒœí’ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘")
    data = fetch_typhoon_data()
    if not data:
        logging.info("ìƒˆë¡œìš´ íƒœí’ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    saved_count = 0
    for item in data:
        unique_str = f"{item['forecast_time'].strftime('%Y%m%d%H%M')}_{item['typ_name']}_{item['typ_lat']}_{item['typ_lon']}"
        typ_no = uuid5(NAMESPACE_DNS, unique_str)
        insert_query = """
        INSERT INTO domestic_typhoon (
            typ_no, forecast_time, typ_name, typ_dir, typ_lat, typ_lon,
            typ_location, intensity, wind_radius
        )
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
        IF NOT EXISTS
        """
        if execute_cassandra(insert_query, (
                typ_no,
                item['forecast_time'],
                item['typ_name'],
                item['typ_dir'],
                item['typ_lat'],
                item['typ_lon'],
                item['typ_location'],
                item['intensity'],
                item['wind_radius']
        )):
            saved_count += 1
            rtd_details = [
                f"typ_name: {item['typ_name']}",
                f"typ_dir: {item['typ_dir']}",
                f"intensity: {item['intensity']}",
                f"wind_radius: {item['wind_radius']}"
            ]
            insert_rtd_data(31, item['forecast_time'], item['typ_location'], rtd_details)
        else:
            logging.error(f"íƒœí’ ì •ë³´ ì €ì¥ ì‹¤íŒ¨ (typ_no: {typ_no})")

    logging.info(f"íƒœí’ ì •ë³´ ì €ì¥ ì™„ë£Œ: {len(data)}ê±´ ì¤‘ {saved_count}ê±´ ì €ì¥ë¨")


# ---------------------------------------------------------------------------
# 5. í™ìˆ˜ ì •ë³´ ìˆ˜ì§‘ (rtd_code 33)
# ---------------------------------------------------------------------------
FLOOD_URLS = [
    ("https://www.water.or.kr/kor/flood/floodwarning/index.do?mode=list&types=1&menuId=16_166_170_172", 172),
    ("https://www.water.or.kr/kor/flood/floodwarning/index.do?mode=list&types=2&menuId=16_166_170_173", 173),
    ("https://www.water.or.kr/kor/flood/floodwarning/index.do?mode=list&types=3&menuId=16_166_170_174", 174),
    ("https://www.water.or.kr/kor/flood/floodwarning/index.do?mode=list&types=4&menuId=16_166_170_175", 175),
]

def get_last_flood_status(region_name: str) -> str:
    """í•´ë‹¹ ì§€ì—­ì˜ ê°€ì¥ ìµœê·¼ ì˜ˆê²½ë³´ ìƒíƒœë¥¼ Pythonì—ì„œ ì¶”ì¶œ"""
    try:
        query = """
        SELECT fld_time, fld_alert FROM RealTimeFlood
        WHERE fld_region = %s ALLOW FILTERING
        """
        result = connector.session.execute(query, (region_name,))
        rows = list(result)
        if not rows:
            return None
        # Pythonì—ì„œ ìµœì‹  ì‹œê°„ìœ¼ë¡œ ì •ë ¬ í›„ ê°€ì¥ ìµœê·¼ ê°’ ë°˜í™˜
        latest_row = max(rows, key=lambda r: r.fld_time)
        return latest_row.fld_alert
    except Exception as e:
        logging.error(f"[ì¤‘ë³µ í•„í„°] ìƒíƒœ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return None


def fetch_flood_data():
    flood_data = []
    for url, code in FLOOD_URLS:
        try:
            resp = session_http.get(url)
            resp.raise_for_status()
        except Exception as e:
            logging.error(f"í™ìˆ˜ ë°ì´í„° ìš”ì²­ ì‹¤íŒ¨ ({url}): {e}")
            continue

        soup = BeautifulSoup(resp.text, "html.parser")
        tbody = soup.select_one("table.basic_table tbody")
        if not tbody:
            logging.info(f"{url}ì—ì„œ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            continue

        for row in tbody.find_all("tr"):
            cells = row.find_all("td")
            if len(cells) < 7:
                continue

            region_txt     = cells[0].get_text(strip=True)
            current_level  = cells[1].get_text(strip=True)
            advisory_level = cells[2].get_text(strip=True)
            warning_level  = cells[3].get_text(strip=True)
            flow_rate      = cells[4].get_text(strip=True)
            alert_status   = cells[5].get_text(strip=True)
            issue_time_txt = cells[6].get_text(strip=True)

            try:
                issued_dt = kst_to_utc(issue_time_txt, "%Y-%m-%d %H:%M")
            except:
                issued_dt = datetime.now(timezone.utc)

            # ë‹¤ë¦¬ëª… ì¶”ì¶œ
            m = re.search(r"\(([^)]+)\)", region_txt)
            bridge_name = m.group(1) if m else None
            coords = bridge_coords.get(bridge_name, {})
            lat = coords.get("bridge_lat")
            lon = coords.get("bridge_lon")

            flood_data.append({
                "code":    code,
                "time":    issued_dt,
                "loc":     region_txt,
                "status":  alert_status,
                "details": [
                    f"í˜„ì¬ ìˆ˜ìœ„: {current_level}m",
                    f"ì£¼ì˜ë³´ ìˆ˜ìœ„: {advisory_level}m",
                    f"ê²½ë³´ ìˆ˜ìœ„: {warning_level}m",
                    f"ìœ ëŸ‰: {flow_rate}ã¥/s",
                    f"ì˜ˆê²½ë³´ í˜„í™©: {alert_status}"
                ],
                "lat":     lat,
                "lon":     lon
            })
    return flood_data

def get_flood_data():
    logging.info("í™ìˆ˜ ì •ë³´ ìˆ˜ì§‘ í•¨ìˆ˜ get_flood_data() ì‹¤í–‰")
    data = fetch_flood_data()
    if not data:
        logging.info("ìƒˆë¡œìš´ í™ìˆ˜ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    saved_count = 0
    for item in data:
        comment_str = "; ".join(item["details"])
        alert_stat = item["status"].replace("ì˜ˆê²½ë³´ í˜„í™©: ", "")
        last_status = get_last_flood_status(item["loc"])

        # ìƒíƒœê°€ ê°™ìœ¼ë©´ ì €ì¥í•˜ì§€ ì•ŠìŒ
        if alert_stat == last_status:
            logging.info(f"[ì¤‘ë³µ ìƒíƒœ] {item['loc']} - '{alert_stat}' ìœ ì§€ â†’ ì €ì¥ ìƒëµ")
            continue

        fld_no = uuid5(NAMESPACE_DNS, f"{item['time'].strftime('%Y%m%d%H%M')}_{item['loc']}_{comment_str}")

        insert_flood_cql = """
        INSERT INTO RealTimeFlood (
            fld_no, fld_region, fld_alert, fld_time, comment
        ) VALUES (%s, %s, %s, %s, %s) IF NOT EXISTS
        """
        if execute_cassandra(insert_flood_cql, (
            fld_no,
            item["loc"],
            alert_stat,
            item["time"],
            comment_str
        )):
            saved_count += 1

            # RTD ì €ì¥ë„ í•¨ê»˜
            insert_rtd_data(
                item["code"],
                item["time"],
                item["loc"],
                item["details"],
                None,
                item.get("lat"),
                item.get("lon")
            )
        else:
            logging.error("RealTimeFlood ì €ì¥ ì‹¤íŒ¨")

    logging.info(f"í™ìˆ˜ ì •ë³´ ì €ì¥ ì™„ë£Œ: {len(data)}ê±´ ì¤‘ {saved_count}ê±´ ì €ì¥ë¨")

# ---------------------------------------------------------------------------
# 6. ê¸°ìƒíŠ¹ë³´(ì£¼ì˜ë³´/ê²½ë³´) ìˆ˜ì§‘ (rtd_codeëŠ” WARNING_CODES ì‚¬ìš©)
# ---------------------------------------------------------------------------
def fetch_warning_data():
    current_date = datetime.now().strftime('%Y%m%d')
    all_warnings = []
    for stn_id, region in STATION_CODES.items():
        url = 'http://apis.data.go.kr/1360000/WthrWrnInfoService/getWthrWrnList'
        params = {
            'serviceKey': 'D0I8CLciGzwIaBmM6g6XitlVfgkLBO83zDl4EnUUoxifvRlSZHu78BqoixtzJg17Gb06up+NHzPXjN0cA7sLOg==',
            'pageNo': '1',
            'numOfRows': '10',
            'dataType': 'XML',
            'stnId': str(stn_id),
            'fromTmFc': current_date,
            'toTmFc': current_date
        }
        try:
            response = session_http.get(url, params=params)
            root = ET.fromstring(response.content)
        except Exception as e:
            logging.error(f"íŠ¹ë³´ ë°ì´í„° ìš”ì²­ ì‹¤íŒ¨ ({stn_id}): {e}")
            continue

        result_code = root.find('.//resultCode')
        if result_code is not None and result_code.text == '03':
            continue

        titles = [item.find('title').text for item in root.findall('.//item') if item.find('title') is not None]
        warnings = preprocess_alert_data(titles, region)
        all_warnings.extend(warnings)
    return all_warnings


def preprocess_alert_data(titles, region):
    processed_data = []
    for title in titles:
        title = re.sub(r'\[íŠ¹ë³´\]\s*', '', title)
        title = re.sub(r'ì œ\d+-\d+í˜¸\s*:\s*', '', title)
        parts = title.split(' / ')
        if len(parts) != 2:
            continue
        date_str, alert_info = parts
        date_str = re.sub(r'(\d{4})\.(\d{2})\.(\d{2})\.(\d{2}):(\d{2})', r'\1-\2-\3 \4:\5', date_str)
        words = okt.morphs(alert_info)
        alert_types = []
        alert_status = ''

        for i, word in enumerate(words):
            if 'ì£¼ì˜ë³´' in word or 'ê²½ë³´' in word:
                if i - 1 >= 0:
                    alert_type = words[i - 1]
                    if alert_type in WARNING_CODES and alert_type not in alert_types:
                        alert_types.append(alert_type)
            elif len(word) == 2:
                alert_status = word

        try:
            formatted_date = kst_to_utc(date_str, "%Y-%m-%d %H:%M")
        except Exception:
            formatted_date = datetime.now(timezone.utc)

        for alert in alert_types:
            processed_data.append({
                "rtd_code": WARNING_CODES[alert],
                "rtd_time": formatted_date,
                "rtd_loc": region,
                "rtd_details": [f"{alert} {alert_status}"]
            })
    return processed_data


def get_warning_data():
    logging.info("ì£¼ì˜ë³´ ì •ë³´ ìˆ˜ì§‘ í•¨ìˆ˜ get_warning_data() ì‹¤í–‰")
    data = fetch_warning_data()
    if not data:
        logging.info("ìƒˆë¡œìš´ ì£¼ì˜ë³´ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    saved_count = 0
    for item in data:
        rtd_code = item['rtd_code']
        rtd_time = item['rtd_time']
        rtd_loc = item['rtd_loc']
        rtd_details = item['rtd_details']
        if rtd_details:
            splitted = rtd_details[0].split()
            if len(splitted) == 2:
                alert_type, alert_stat = splitted
            else:
                alert_type = splitted[0]
                alert_stat = "ì •ë³´ì—†ìŒ"
        else:
            alert_type = "ì •ë³´ì—†ìŒ"
            alert_stat = "ì •ë³´ì—†ìŒ"
        unique_str = f"{rtd_loc}_{alert_type}_{alert_stat}_{rtd_time.strftime('%Y%m%d%H%M')}"
        announce_no = uuid5(NAMESPACE_DNS, unique_str)
        insert_query = """
        INSERT INTO ForecastAnnouncement (
            announce_no, disaster_region, alert_type, alert_stat, announce_time, comment
        )
        VALUES (%s, %s, %s, %s, %s, %s)
        IF NOT EXISTS
        """
        comment = f"ê¸°ìƒíŠ¹ë³´ ìë™ ìˆ˜ì§‘ / {alert_type} {alert_stat}"
        if execute_cassandra(insert_query, (announce_no, rtd_loc, alert_type, alert_stat, rtd_time, comment)):
            saved_count += 1
            insert_rtd_data(rtd_code, rtd_time, rtd_loc, rtd_details)
        else:
            logging.error(f"ì£¼ì˜ë³´ ì •ë³´ ì €ì¥ ì‹¤íŒ¨ (announce_no: {announce_no})")
    logging.info(f"ì£¼ì˜ë³´ ì •ë³´ ì €ì¥ ì™„ë£Œ: {len(data)}ê±´ ì¤‘ {saved_count}ê±´ ì €ì¥ë¨")


# ---------------------------------------------------------------------------
# 7. ì¬ë‚œë¬¸ì í¬ë¡¤ëŸ¬ (ëª…ë ¹ì–´ ì¸í„°í˜ì´ìŠ¤ í¬í•¨)
# ---------------------------------------------------------------------------
class DisasterMessageCrawler:
    def __init__(self):
        chrome_options = Options()
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        self.driver = webdriver.Chrome(service=Service(CHROME_DRIVER_PATH), options=chrome_options)
        self.driver.set_page_load_timeout(30)
        self.wait = WebDriverWait(self.driver, 20)
        self.session = connector.session
        self.seen_ids = set()

    def message_exists(self, msg_id):
        from cassandra.query import SimpleStatement
        result = self.session.execute(
            SimpleStatement("SELECT message_id FROM disaster_message WHERE message_id = %s"),
            (msg_id,)
        )
        return result.one() is not None

    def backup_messages(self, messages):
        from cassandra.query import SimpleStatement

        for msg in messages:
            logging.info(f"âœ… disaster_message INSERT ì‹œë„ ì¤‘: {msg['message_id']}")
            try:
                # 1) disaster_message í…Œì´ë¸”ì— ì €ì¥
                self.session.execute(SimpleStatement("""
                    INSERT INTO disaster_message (
                        message_id, emergency_level, DM_ntype, DM_stype,
                        issuing_agency, issued_at, message_content
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s) IF NOT EXISTS
                """, ()
                ), (
                    int(msg['message_id']),
                    msg['emergency_level'],
                    msg['DM_ntype'],
                    msg['DM_stype'],
                    msg['issuing_agency'],
                    msg['issued_at'],
                    msg['message_content']
                ))
                logging.info(f"âœ… disaster_message ì €ì¥ ì„±ê³µ: {msg['message_id']}")

                # 2) NER ëª¨ë¸ë¡œ ë©”ì‹œì§€ ë‚´ìš©ì—ì„œ ì§€ì—­ ì¶”ì¶œ
                full_text = msg['message_content']
                extracted_regions = extract_locations(full_text)
                logging.info(f"ğŸ” ì¶”ì¶œëœ ì§€ì—­ë“¤: {extracted_regions}")

                if extracted_regions:
                    # â†’ (ìƒëµ) ì •ìƒì ì¸ ì§€ì—­ë³„ RTD ì €ì¥ ë¡œì§
                    for rtd_loc in extracted_regions:
                        region_cd = get_regioncode(rtd_loc)
                        coords    = geocoding(rtd_loc)
                        lat       = float(coords.get('lat')) if coords.get('lat') else None
                        lng       = float(coords.get('lng')) if coords.get('lng') else None

                        rtd_details = [
                            f"level: {msg['emergency_level']}",
                            f"type: {msg['DM_ntype']}",
                            f"content: {msg['message_content']}"
                        ]
                        insert_rtd_data(
                            21,
                            msg['issued_at'],
                            rtd_loc,
                            rtd_details,
                            region_cd,
                            lat,
                            lng
                        )
                        logging.info(f"âœ… rtd_db ì €ì¥ ì™„ë£Œ (loc: {rtd_loc})")

                else:
                    # ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ issuing_agency ë¥¼ ì§€ì—­ëª…ìœ¼ë¡œ ì‚¬ìš©
                    fallback_loc = msg['issuing_agency']
                    logging.warning(f"âš ï¸ ì§€ì—­ëª… ë¯¸ì¶”ì¶œ â†’ issuing_agency ë¥¼ ì§€ì—­ëª…ìœ¼ë¡œ ì‚¬ìš©: {fallback_loc}")

                    # issuing_agency ì— ëŒ€í•´ geocode & regioncode ìˆ˜í–‰
                    region_cd = get_regioncode(fallback_loc)
                    coords    = geocoding(fallback_loc)
                    lat       = float(coords.get('lat')) if coords.get('lat') else None
                    lng       = float(coords.get('lng')) if coords.get('lng') else None

                    rtd_details = [
                        f"level: {msg['emergency_level']}",
                        f"type: {msg['DM_ntype']}",
                        f"content: {msg['message_content']}"
                    ]
                    insert_rtd_data(
                        21,
                        msg['issued_at'],
                        fallback_loc,
                        rtd_details,
                        region_cd,
                        lat,
                        lng
                    )
                    logging.info(f"âœ… rtd_db ì €ì¥ ì™„ë£Œ (fallback loc: {fallback_loc})")

            except Exception as e:
                logging.error(f"âŒ backup_messages ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    # ---------------------------------------------------------------------------
    # RTD DB í•­ëª© ìˆ˜ì • ë¡œì§ ì¶”ê°€
    # ---------------------------------------------------------------------------
    def edit_rtd_entry(self):
        from cassandra.query import SimpleStatement
        import uuid

        # 1) ìˆ˜ì •í•  ID ì…ë ¥
        id_input = input("ìˆ˜ì •í•  RTD IDë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        try:
            id_uuid = uuid.UUID(id_input)
        except ValueError:
            print("ìœ íš¨í•œ UUID í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
            return

        # 2) í˜„ì¬ ê°’ ì¡°íšŒ ë° ì¶œë ¥
        stmt = SimpleStatement("SELECT * FROM rtd_db WHERE id = %s ALLOW FILTERING")
        row = self.session.execute(stmt, (id_uuid,)).one()
        if not row:
            print("í•´ë‹¹ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        print("í˜„ì¬ ê°’:", row)

        # 3) ìˆ˜ì •í•  ì»¬ëŸ¼ ì…ë ¥
        cols_str = input("ìˆ˜ì •í•  ì»¬ëŸ¼ëª…ì„ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        cols = [c.strip() for c in cols_str.split(",") if c.strip()]
        if not cols:
            print("ìˆ˜ì •í•  ì»¬ëŸ¼ì„ í•˜ë‚˜ ì´ìƒ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")
            return

        # 4) ê° ì»¬ëŸ¼ì— ëŒ€í•œ ìƒˆë¡œìš´ ê°’ ì…ë ¥
        updates = {}
        for col in cols:
            val = input(f"{col}ì˜ ìƒˆë¡œìš´ ê°’ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            updates[col] = val

        # 5) UPDATE CQL ìƒì„± ë° ì‹¤í–‰
        set_clause = ", ".join(f"{col} = %({col})s" for col in updates)
        query = f"UPDATE rtd_db SET {set_clause} WHERE id = %(id)s"
        params = {**updates, "id": id_uuid}
        try:
            self.session.execute(query, params)
            print("ìˆ˜ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"ìˆ˜ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # process_commandì— edit_rtd ëª…ë ¹ì–´ ì²˜ë¦¬ ì¶”ê°€
    # display_helpì—ë„ ì•ˆë‚´ ë¬¸êµ¬ ì¶”ê°€

    def check_and_save(self):
        messages = self.check_messages()
        if messages:
            self.backup_messages(messages)
            logging.info(f"ìŠ¤ì¼€ì¤„ëŸ¬: ì‹ ê·œ ë©”ì‹œì§€ {len(messages)}ê±´ ì €ì¥ë¨")
        else:
            logging.info("ìŠ¤ì¼€ì¤„ëŸ¬: ì‹ ê·œ ì¬ë‚œë¬¸ì ì—†ìŒ")

    def show_status(self):
        global FCM_NOTIFICATIONS_ENABLED
        print("=== ì €ì¥ í˜„í™© ===")
        for table in [
            "airinform", "airgrade", "domestic_earthquake",
            "domestic_typhoon", "disaster_message", "forecastannouncement",
            "realtimeflood", "rtd_db", "user_device"
        ]:
            try:
                stmt = SimpleStatement(f"SELECT count(*) FROM {table};")
                result = connector.session.execute(stmt)
                for row in result:
                    print(f"{table}: {row.count}ê±´")
            except Exception as e:
                print(f"{table}: ì˜¤ë¥˜ ë°œìƒ ({str(e).splitlines()[0]})")
        print(f"FCM ì•Œë¦¼ ìƒíƒœ: {'í™œì„±í™”' if FCM_NOTIFICATIONS_ENABLED else 'ë¹„í™œì„±í™”'}")
        print("=================")

    def process_command(self, cmd):
        global FCM_NOTIFICATIONS_ENABLED
        if cmd in ["q", "exit"]:
            logging.info("ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ")
            return True
        elif cmd == "1":
            self.show_status()
        elif cmd == "2":
            logging.info("ëŒ€ê¸° ì˜ˆë³´ ìˆ˜ì§‘ ì‹œì‘")
            get_air_inform()
            logging.info("ëŒ€ê¸° ì˜ˆë³´ ìˆ˜ì§‘ ì™„ë£Œ")
        elif cmd == "3":
            logging.info("ì‹¤ì‹œê°„ ë¯¸ì„¸ë¨¼ì§€ ìˆ˜ì§‘ ì‹œì‘")
            get_air_grade()
            logging.info("ë¯¸ì„¸ë¨¼ì§€ ìˆ˜ì§‘ ì™„ë£Œ")
        elif cmd == "4":
            logging.info("ì§€ì§„ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘")
            fetch_earthquake_data()
            logging.info("ì§€ì§„ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")
        elif cmd == "5":
            logging.info("ì „ì²´ ìˆ˜ì§‘ ì‹œì‘")
            get_air_inform()
            get_air_grade()
            fetch_earthquake_data()
            get_typhoon_data()
            logging.info("ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ")
        elif cmd == "6":
            logging.info("íƒœí’ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘")
            get_typhoon_data()
            logging.info("íƒœí’ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")
        elif cmd == "7":
            logging.info("í™ìˆ˜ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘")
            get_flood_data()
            logging.info("í™ìˆ˜ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")
        elif cmd == "8":
            logging.info("ì£¼ì˜ë³´ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘")
            get_warning_data()
            logging.info("ì£¼ì˜ë³´ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")
        elif cmd == "9":
            logging.info("ì¬ë‚œë¬¸ì ìˆ˜ì§‘ ì‹œì‘")
            messages = self.check_messages()
            if messages:
                self.backup_messages(messages)
                logging.info(f"ì‹ ê·œ ë©”ì‹œì§€ {len(messages)}ê±´ ì €ì¥ë¨")
            else:
                logging.info("ì‹ ê·œ ì¬ë‚œë¬¸ì ì—†ìŒ")
        elif cmd == "toggle_fcm":
            FCM_NOTIFICATIONS_ENABLED = not FCM_NOTIFICATIONS_ENABLED
            print(f"FCM ì•Œë¦¼ì´ {'í™œì„±í™”' if FCM_NOTIFICATIONS_ENABLED else 'ë¹„í™œì„±í™”'}ë˜ì—ˆìŠµë‹ˆë‹¤.")
        elif cmd.startswith("set_interval"):
            tokens = cmd.split()
            if len(tokens) != 3:
                print("ì‚¬ìš©ë²•: set_interval <task_name> <ì´ˆ>")
            else:
                task_name = tokens[1]
                try:
                    interval = int(tokens[2])
                    if scheduler.update_interval(task_name, interval):
                        print(f"{task_name}ì˜ ì£¼ê¸°ê°€ {interval}ì´ˆë¡œ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    else:
                        print(f"ì‘ì—… '{task_name}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                except Exception:
                    print("ì˜¬ë°”ë¥¸ ì£¼ê¸°(ì´ˆ)ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif cmd == "list_intervals":
            tasks = scheduler.list_tasks()
            print("=== ë“±ë¡ëœ ìŠ¤ì¼€ì¤„ ì‘ì—… ===")
            for name, interval in tasks.items():
                print(f"{name}: {interval}ì´ˆ")
            print("=======================")
        elif cmd == "edit_rtd":
            self.edit_rtd_entry()
        elif cmd == "?":
            self.display_help()
        else:
            print("ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return False

    def display_help(self):
        print("ëª…ë ¹ì–´ ì•ˆë‚´:")
        print(" 1 â†’ ì €ì¥ í˜„í™© ë³´ê¸°")
        print(" 2 â†’ ëŒ€ê¸° ì˜ˆë³´ ì •ë³´ ìˆ˜ì§‘")
        print(" 3 â†’ ì‹¤ì‹œê°„ ë¯¸ì„¸ë¨¼ì§€ ìˆ˜ì§‘")
        print(" 4 â†’ ì§€ì§„ ì •ë³´ ìˆ˜ì§‘")
        print(" 5 â†’ ì „ì²´ ìˆ˜ì§‘ (ëŒ€ê¸° ì˜ˆë³´ + ë¯¸ì„¸ë¨¼ì§€ + ì§€ì§„ + íƒœí’)")
        print(" 6 â†’ íƒœí’ ì •ë³´ ìˆ˜ì§‘")
        print(" 7 â†’ í™ìˆ˜ ì •ë³´ ìˆ˜ì§‘")
        print(" 8 â†’ ê¸°ìƒíŠ¹ë³´(ì£¼ì˜ë³´/ê²½ë³´) ì •ë³´ ìˆ˜ì§‘")
        print(" 9 â†’ ì¬ë‚œë¬¸ì ìˆ˜ì§‘")
        print(" toggle_fcm â†’ FCM ì•Œë¦¼ í™œì„±í™”/ë¹„í™œì„±í™”")
        print(" set_interval <task_name> <ì´ˆ> â†’ ì§€ì • ì‘ì—… ì£¼ê¸° ìˆ˜ì •")
        print(" list_intervals â†’ í˜„ì¬ ë“±ë¡ëœ ìŠ¤ì¼€ì¤„ ì£¼ê¸° í™•ì¸")
        print(" edit_rtd â†’ rtd_db í•­ëª© ìˆ˜ì • (ID ì…ë ¥ í›„ ì»¬ëŸ¼/ê°’ ìˆœì°¨ì ìœ¼ë¡œ ì…ë ¥)")
        print(" ? â†’ ëª…ë ¹ì–´ ë„ì›€ë§")
        print(" q ë˜ëŠ” exit â†’ ì¢…ë£Œ")

    def check_messages(self):
        self.driver.get(
            'https://www.safekorea.go.kr/idsiSFK/neo/sfk/cs/sfc/dis/disasterMsgList.jsp?menuSeq=603'
        )
        time.sleep(5)

        messages = []
        rows = self.driver.find_elements(By.CSS_SELECTOR, "table.boardList_table tbody tr")
        for row in rows:
            row_id = row.get_attribute('id')
            try:
                idx = re.search(r'disasterSms_tr_(\d+)_apiData1', row_id).group(1)
            except:
                continue

            try:
                msg_id = int(row.find_element(By.ID, f"disasterSms_tr_{idx}_MD101_SN").text.strip())
                emergency_level = row.find_element(By.ID, f"disasterSms_tr_{idx}_EMRGNCY_STEP_NM").text.strip()
                ntype = row.find_element(By.ID, f"disasterSms_tr_{idx}_DSSTR_SE_NM").text.strip()
                location = row.find_element(By.ID, f"disasterSms_tr_{idx}_MSG_LOC").text.strip()
                issued_at_str = row.find_element(By.ID, f"disasterSms_tr_{idx}_CREATE_DT").text.strip()
                content = row.find_element(By.ID, f"disasterSms_tr_{idx}_MSG_CN").get_attribute("title").strip()
            except Exception as e:
                logging.error(f"í•„ë“œ ì¶”ì¶œ ì˜¤ë¥˜ (row {row_id}): {e}")
                continue

            if msg_id in self.seen_ids or self.message_exists(msg_id):
                continue

            try:
                issued_at = datetime.strptime(issued_at_str, "%Y/%m/%d %H:%M:%S")
            except Exception:
                issued_at = datetime.now()

            message = {
                "message_id": msg_id,
                "emergency_level": emergency_level,
                "DM_ntype": ntype,
                "DM_stype": "",
                "issuing_agency": location,
                "issued_at": issued_at,
                "message_content": content
            }

            self.seen_ids.add(msg_id)
            messages.append(message)

        logging.info(f"ìˆ˜ì§‘ëœ ë©”ì‹œì§€ ê°œìˆ˜: {len(messages)}")
        return messages

    def monitor(self):
        logging.info("ì‹¤ì‹œê°„ ì¬ë‚œë¬¸ì ìˆ˜ì§‘ ì‹œì‘")
        self.display_help()
        last_check_time = time.time()
        while True:
            try:
                if sys.stdin in select.select([sys.stdin], [], [], 0)[0]:
                    cmd = input().strip().lower()
                    if self.process_command(cmd):
                        break
                if time.time() - last_check_time > 60:
                    messages = self.check_messages()
                    if messages:
                        logging.info("ì‹ ê·œ ë©”ì‹œì§€ ë°œê²¬")
                        print(json.dumps(messages, ensure_ascii=False, indent=2, default=str))
                        self.backup_messages(messages)
                    else:
                        logging.info("ì‹ ê·œ ë©”ì‹œì§€ ì—†ìŒ")
                        print("60ì´ˆ ëŒ€ê¸° ì¤‘... (ëª…ë ¹ì–´ ì…ë ¥ ê°€ëŠ¥: 1~8, set_interval, list_intervals, q ë“±)")
                    last_check_time = time.time()
                time.sleep(1)
            except Exception as e:
                logging.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
                time.sleep(60)
        self.driver.quit()


# ---------------------------------------------------------------------------
# ë©”ì¸ í•¨ìˆ˜: ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ë° ë°ì´í„° ìˆ˜ì§‘/ì¬ë‚œë¬¸ì ëª¨ë‹ˆí„°ë§ ì‹¤í–‰
# ---------------------------------------------------------------------------
def main():
    logging.info("ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")

    # ìŠ¤ì¼€ì¤„ëŸ¬ì— ì‘ì—… ë“±ë¡ (ê¸°ë³¸ ì£¼ê¸°: ì´ˆ ë‹¨ìœ„)
    scheduler.add_task("air_inform", 36000, get_air_inform)  # ëŒ€ê¸° ì˜ˆë³´: 10ì‹œê°„
    scheduler.add_task("air_grade", 36000, get_air_grade)  # ì‹¤ì‹œê°„ ë¯¸ì„¸ë¨¼ì§€: 10ì‹œê°„
    scheduler.add_task("earthquake", 600, fetch_earthquake_data)  # ì§€ì§„: 10ë¶„
    scheduler.add_task("typhoon", 3600, get_typhoon_data)  # íƒœí’: 1ì‹œê°„
    scheduler.add_task("flood", 36000, get_flood_data)  # í™ìˆ˜: 10ì‹œê°„
    scheduler.add_task("warning", 36000, get_warning_data)  # ê¸°ìƒíŠ¹ë³´: 10ì‹œê°„
    scheduler.add_task("disaster_messages", 600, partial(DisasterMessageCrawler().check_and_save))

    # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ)
    scheduler.start()

    # ì´ˆê¸° ìˆ˜ì§‘ í•¨ìˆ˜ ì‹¤í–‰ (ì˜µì…˜)
    get_air_inform()
    get_air_grade()
    fetch_earthquake_data()
    get_typhoon_data()
    get_flood_data()
    get_warning_data()

    # ì¬ë‚œë¬¸ì ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ëª…ë ¹ì–´ ê¸°ë°˜ ì¸í„°í˜ì´ìŠ¤)
    DisasterMessageCrawler().monitor()


if __name__ == "__main__":
    main()