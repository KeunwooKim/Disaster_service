import os
import torch
from transformers import BertTokenizerFast, BertForTokenClassification

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) ëª¨ë¸ ë¡œë“œ
BASE_DIR = os.path.dirname(__file__)
MODEL_PATH = os.path.join(BASE_DIR, "ner_model")

tokenizer_loc = BertTokenizerFast.from_pretrained(MODEL_PATH)
model_loc = BertForTokenClassification.from_pretrained(MODEL_PATH)
model_loc.config.id2label = {0: "O", 1: "B-ORG", 2: "B-LOC", 3: "I-LOC", 4: "I-ORG"}
model_loc.config.label2id = {v: k for k, v in model_loc.config.id2label.items()}
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_loc.to(device)
model_loc.eval()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_locations(text: str) -> list:
    """
    ì¬ë‚œ ë¬¸ì ë‚´ì—ì„œ B-LOC/I-LOCë¡œ ì˜ˆì¸¡ëœ ì§€ì—­ëª…ì„ ëª¨ë‘ ì¶”ì¶œí•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    íŠ¹ìˆ˜ í† í°(offset spanì´ 0ì¸ í† í°)ì„ ë¬´ì‹œí•˜ë©°, ì¤‘ë³µ ì œê±° ë° ìµœì†Œ ê¸¸ì´ 2ì ì´ìƒì˜ ì§€ì—­ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if not text:
        return []

    encoding = tokenizer_loc(
        text,
        return_offsets_mapping=True,
        truncation=True,
        max_length=512,
        return_tensors="pt"
    )
    input_ids = encoding["input_ids"].to(device)
    attention_mask = encoding["attention_mask"].to(device)
    offsets = encoding["offset_mapping"][0].tolist()

    with torch.no_grad():
        logits = model_loc(input_ids, attention_mask=attention_mask).logits[0]
    preds = torch.argmax(logits, dim=-1).tolist()

    regions = []
    current_span = None

    for idx, (label_id, (start, end)) in enumerate(zip(preds, offsets)):
        # special token or no span
        if start == end:
            continue
        label = model_loc.config.id2label[label_id]

        if label == "B-LOC":
            if current_span:
                regions.append(tuple(current_span))
            current_span = [start, end]
        elif label == "I-LOC" and current_span:
            current_span[1] = end
        else:
            if current_span:
                regions.append(tuple(current_span))
                current_span = None

    if current_span:
        regions.append(tuple(current_span))

    extracted = []
    for s, e in regions:
        segment = text[s:e].strip()
        if len(segment) >= 2 and segment not in extracted:
            extracted.append(segment)
    return extracted

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    examples = [
        "21:48 ë‚¨êµ¬ ì„ ì•”ë™(ë‘ì™•ì‚¬ê±°ë¦¬, ê°ë‚˜ë¬´ì§„ì‚¬ê±°ë¦¬ ë°©ë©´)í™”ì¬ ë°œìƒ. ì¸ê·¼ ì£¼ë¯¼ì€ ì£¼ì˜ ë°”ëë‹ˆë‹¤.",
        "ì˜¤ëŠ˜ 13:48 ì˜¨ì–‘ì ìš´í™”ë¦¬ ì‚°119-1 ì‚°ë¶ˆ ë°œìƒ. ë§ˆì„ ì£¼ë¯¼ì€ ëŒ€í”¼í•˜ì„¸ìš”.",
        "ì„œìš¸íŠ¹ë³„ì‹œ ì„±ë™êµ¬ ì™•ì‹­ë¦¬ë¡œ 123, í•œì–‘ëŒ€ ì• íš¡ë‹¨ë³´ë„ ì¸ê·¼ì—ì„œ ì‚¬ê³  ë°œìƒ.",
        "ê¸°ìƒì²­ ì˜ˆë³´: ê²½ê¸°ë„ ìˆ˜ì›ì‹œ ê¶Œì„ êµ¬ í˜¸ë§¤ì‹¤ë™ì— í˜¸ìš°ì£¼ì˜ë³´ ë°œíš¨ ì¤‘."
    ]

    for sent in examples:
        print(f"ë¬¸ì¥: {sent}")
        print(f"ì¶”ì¶œëœ ì§€ì—­: {extract_locations(sent)}")
        print("â”€" * 40)

    print("ğŸ” ì§ì ‘ ì…ë ¥ í…ŒìŠ¤íŠ¸ (ì¢…ë£Œí•˜ë ¤ë©´ ë¹ˆ ì¤„)")
    while True:
        text = input("ë¬¸ì¥ ì…ë ¥> ").strip()
        if not text:
            break
        print(f"ì¶”ì¶œëœ ì§€ì—­: {extract_locations(text)}\n")
